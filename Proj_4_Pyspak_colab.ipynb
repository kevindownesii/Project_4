{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "a_KW73O2e3dw",
        "outputId": "90888fdd-b860-48c4-dd1b-c38784f2b66f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bd8349de-0173-4d1f-aa98-5aed9af2313d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bd8349de-0173-4d1f-aa98-5aed9af2313d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving housing_data.csv to housing_data.csv\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [929 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,922 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,392 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,093 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,474 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,552 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,187 kB]\n",
            "Fetched 12.9 MB in 2s (5,968 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.x  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.4.0'\n",
        "spark_version = 'spark-3.5.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2XbWNf1Te5fM"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "from pyspark.sql import SparkSession\n",
        "import time\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wOJqxG_RPSwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9fee66a-fb82-4441-c70b-a91ee858a169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------------+-------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
            "|        id|           date|  price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|grade|sqft_above|sqft_basement|yr_built|yr_renovated|zipcode|    lat|    long|sqft_living15|sqft_lot15|\n",
            "+----------+---------------+-------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
            "|7229300521|20141013T000000| 231300|       2|        1|       1180|    5650|     1|         0|   0|        3|    7|      1180|            0|    1955|           0|  98178|47.5112|-122.257|         1340|      5650|\n",
            "|6414100192|20141209T000000| 538000|       3|     2.25|       2570|    7242|     2|         0|   0|        3|    7|      2170|          400|    1951|        1991|  98125| 47.721|-122.319|         1690|      7639|\n",
            "|5631500400|20150225T000000| 180000|       2|        1|        770|   10000|     1|         0|   0|        3|    6|       770|            0|    1933|           0|  98028|47.7379|-122.233|         2720|      8062|\n",
            "|2487200875|20141209T000000| 604000|       4|        3|       1960|    5000|     1|         0|   0|        5|    7|      1050|          910|    1965|           0|  98136|47.5208|-122.393|         1360|      5000|\n",
            "|1954400510|20150218T000000| 510000|       3|        2|       1680|    8080|     1|         0|   0|        3|    8|      1680|            0|    1987|           0|  98074|47.6168|-122.045|         1800|      7503|\n",
            "|7237550310|20140512T000000|1225000|       4|      4.5|       5420|  101930|     1|         0|   0|        3|   11|      3890|         1530|    2001|           0|  98053|47.6561|-122.005|         4760|    101930|\n",
            "|1321400060|20140627T000000| 257500|       3|     2.25|       1715|    6819|     2|         0|   0|        3|    7|      1715|            0|    1995|           0|  98003|47.3097|-122.327|         2238|      6819|\n",
            "|2008000270|20150115T000000| 291850|       3|      1.5|       1060|    9711|     1|         0|   0|        3|    7|      1060|            0|    1963|           0|  98198|47.4095|-122.315|         1650|      9711|\n",
            "|2414600126|20150415T000000| 229500|       3|        1|       1780|    7470|     1|         0|   0|        3|    7|      1050|          730|    1960|           0|  98146|47.5123|-122.337|         1780|      8113|\n",
            "|3793500160|20150312T000000| 323000|       3|      2.5|       1890|    6560|     2|         0|   0|        3|    7|      1890|            0|    2003|           0|  98038|47.3684|-122.031|         2390|      7570|\n",
            "|1736800520|20150403T000000| 662500|       3|      2.5|       3560|    9796|     1|         0|   0|        3|    8|      1860|         1700|    1965|           0|  98007|47.6007|-122.145|         2210|      8925|\n",
            "|9212900260|20140527T000000| 468000|       2|        1|       1160|    6000|     1|         0|   0|        4|    7|       860|          300|    1942|           0|  98115|  47.69|-122.292|         1330|      6000|\n",
            "| 114101516|20140528T000000| 310000|       3|        1|       1430|   19901|   1.5|         0|   0|        4|    7|      1430|            0|    1927|           0|  98028|47.7558|-122.229|         1780|     12697|\n",
            "|6054650070|20141007T000000| 400000|       3|     1.75|       1370|    9680|     1|         0|   0|        4|    7|      1370|            0|    1977|           0|  98074|47.6127|-122.045|         1370|     10208|\n",
            "|1175000570|20150312T000000| 530000|       5|        2|       1810|    4850|   1.5|         0|   0|        3|    7|      1810|            0|    1900|           0|  98107|  47.67|-122.394|         1360|      4850|\n",
            "|9297300055|20150124T000000| 650000|       4|        3|       2950|    5000|     2|         0|   3|        3|    9|      1980|          970|    1979|           0|  98126|47.5714|-122.375|         2140|      4000|\n",
            "|1875500060|20140731T000000| 395000|       3|        2|       1890|   14040|     2|         0|   0|        3|    7|      1890|            0|    1994|           0|  98019|47.7277|-121.962|         1890|     14018|\n",
            "|6865200140|20140529T000000| 485000|       4|        1|       1600|    4300|   1.5|         0|   0|        4|    7|      1600|            0|    1916|           0|  98103|47.6648|-122.343|         1610|      4300|\n",
            "|  16000397|20141205T000000| 189000|       2|        1|       1200|    9850|     1|         0|   0|        4|    7|      1200|            0|    1921|           0|  98002|47.3089| -122.21|         1060|      5095|\n",
            "|7983200060|20150424T000000| 230000|       3|        1|       1250|    9774|     1|         0|   0|        4|    7|      1250|            0|    1969|           0|  98003|47.3343|-122.306|         1280|      8850|\n",
            "+----------+---------------+-------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Read in the AWS S3 bucket into a DataFrame.\n",
        "from pyspark import SparkFiles\n",
        "#url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n",
        "#spark.sparkContext.addFile(url)\n",
        "homes_df = spark.read.csv(SparkFiles.get(\"/content/housing_data.csv\"), sep=\",\", header=True)\n",
        "homes_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RoljcJ7WPpnm"
      },
      "outputs": [],
      "source": [
        "# 2. Create a temporary view of the DataFrame.\n",
        "homes_df.createOrReplaceTempView('home_sales')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "L6fkwOeOmqvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221d149d-bf2c-42b4-8b6a-f7803827b200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|YEAR|AVERAGE_PRICE|\n",
            "+----+-------------+\n",
            "|2015|    940324.31|\n",
            "|2014|    712226.14|\n",
            "|2013|    729881.97|\n",
            "|2012|    606583.35|\n",
            "|2011|     627180.8|\n",
            "|2010|    605018.37|\n",
            "|2009|     553977.4|\n",
            "|2008|    806330.48|\n",
            "|2007|    764035.91|\n",
            "|2006|    738474.06|\n",
            "|2005|    667901.81|\n",
            "|2004|    658634.77|\n",
            "|2003|    615643.01|\n",
            "|2002|    640074.65|\n",
            "|2001|    731348.23|\n",
            "|2000|    761055.96|\n",
            "|1999|     676729.2|\n",
            "|1998|     653719.7|\n",
            "|1997|    624072.42|\n",
            "|1996|    715369.01|\n",
            "+----+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3. What is the average price for a four bedroom house sold per year, rounded to two decimal places?\n",
        "a = \"\"\"\n",
        "SELECT\n",
        "  YEAR(yr_built) AS YEAR,\n",
        "  ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
        "FROM home_sales\n",
        "WHERE bedrooms = 4\n",
        "GROUP BY YEAR\n",
        "ORDER BY YEAR DESC\n",
        "\"\"\"\n",
        "spark.sql(a).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l8p_tUS8h8it",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e303896c-efca-48d8-bbb4-7f7e76c96e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|YEAR|AVERAGE_PRICE|\n",
            "+----+-------------+\n",
            "|2015|    1550000.0|\n",
            "|2014|    765652.96|\n",
            "|2013|    477595.38|\n",
            "|2012|     537490.0|\n",
            "|2011|     645250.0|\n",
            "|2010|     554125.0|\n",
            "|2009|    570746.94|\n",
            "|2008|    609063.64|\n",
            "|2007|     610093.1|\n",
            "|2006|    618956.98|\n",
            "|2005|    634251.56|\n",
            "|2004|    635366.67|\n",
            "|2003|    724457.69|\n",
            "|2002|    672418.75|\n",
            "|2001|    727029.41|\n",
            "|2000|    683632.86|\n",
            "|1999|     766570.4|\n",
            "|1998|     763375.0|\n",
            "|1997|     612475.0|\n",
            "|1996|    1490000.0|\n",
            "+----+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4. What is the average price of a home for each year the home was built,\n",
        "# that have 3 bedrooms and 3 bathrooms, rounded to two decimal places?\n",
        "b =  \"\"\"\n",
        "SELECT\n",
        "  YEAR(yr_built) AS YEAR,\n",
        "  ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
        "FROM home_sales\n",
        "WHERE bedrooms = 3\n",
        "and bathrooms = 3\n",
        "GROUP BY YEAR(yr_built)\n",
        "ORDER BY YEAR DESC\n",
        "\"\"\"\n",
        "spark.sql(b).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y-Eytz64liDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95cc0dae-d233-41d7-9afe-e0d33067dc50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+\n",
            "|YEAR_BUILT|AVERAGE_PRICE|\n",
            "+----------+-------------+\n",
            "|      2015|    1550000.0|\n",
            "|      2014|    933142.67|\n",
            "|      2013|     570685.0|\n",
            "|      2012|     572500.0|\n",
            "|      2011|     639750.0|\n",
            "|      2010|     721000.0|\n",
            "|      2009|    1011250.0|\n",
            "|      2008|    1064500.0|\n",
            "|      2007|    949777.78|\n",
            "|      2006|    954444.69|\n",
            "|      2005|    792503.85|\n",
            "|      2004|     719500.0|\n",
            "|      2003|     851750.0|\n",
            "|      2002|     863200.0|\n",
            "|      2001|     860875.0|\n",
            "|      2000|    795511.25|\n",
            "|      1999|    845605.56|\n",
            "|      1998|    922142.86|\n",
            "|      1997|     679970.0|\n",
            "|      1996|    1490000.0|\n",
            "+----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5. What is the average price of a home for each year the home was built,\n",
        "# that have 3 bedrooms, 3 bathrooms, with two floors,\n",
        "# and are greater than or equal to 2,000 square feet, rounded to two decimal places?\n",
        "c = \"\"\"\n",
        "SELECT\n",
        "  YEAR(yr_built) AS YEAR_BUILT,\n",
        "  ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
        "FROM home_sales\n",
        "WHERE bedrooms = 3\n",
        "and bathrooms = 3\n",
        "and sqft_living >= 2000\n",
        "and floors = 2\n",
        "GROUP BY yr_built\n",
        "ORDER BY yr_built DESC\n",
        "\"\"\"\n",
        "spark.sql(c).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUrfgOX1pCRd",
        "outputId": "5327e9b1-f995-49a9-c24d-a0f8e7449a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|view|AVERAGE_PRICE|\n",
            "+----+-------------+\n",
            "|   4|   1463711.24|\n",
            "|   3|    971965.27|\n",
            "|   2|    792400.89|\n",
            "|   1|    812280.84|\n",
            "|   0|    496564.67|\n",
            "+----+-------------+\n",
            "\n",
            "--- 0.9994776248931885 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# 6. What is the average price of a home per \"view\" rating, rounded to two decimal places,\n",
        "# having an average home price greater than or equal to $350,000? Order by descending view rating.\n",
        "# Although this is a small dataset, determine the run time for this query.\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "d = \"\"\"\n",
        "SELECT\n",
        "view,\n",
        "ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
        "FROM home_sales\n",
        "GROUP BY view\n",
        "HAVING AVG(price) >= 350000\n",
        "ORDER BY view desc\n",
        "\"\"\"\n",
        "spark.sql(d).show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KAhk3ZD2tFy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdccc99d-b138-4699-e6fd-b2c6e97ee602"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 7. Cache the the temporary table home_sales.\n",
        "spark.sql('cache table home_sales')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4opVhbvxtL-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c1b85f-1fd3-4e9b-b0e2-0a7edfe32303"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# 8. Check if the table is cached.\n",
        "spark.catalog.isCached('home_sales')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GnL46lwTSEk",
        "outputId": "73334bc0-fb5a-4d1a-e1ce-9865778fc7ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|view|AVERAGE_PRICE|\n",
            "+----+-------------+\n",
            "|   4|   1463711.24|\n",
            "|   3|    971965.27|\n",
            "|   2|    792400.89|\n",
            "|   1|    812280.84|\n",
            "|   0|    496564.67|\n",
            "+----+-------------+\n",
            "\n",
            "--- 0.5703532695770264 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# 9. Using the cached data, run the last query above, that calculates\n",
        "# the average price of a home per \"view\" rating, rounded to two decimal places,\n",
        "# having an average home price greater than or equal to $350,000.\n",
        "# Determine the runtime and compare it to the uncached runtime.\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "e = \"\"\"\n",
        "SELECT\n",
        "view,\n",
        "ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
        "FROM home_sales\n",
        "GROUP BY view\n",
        "HAVING AVG(price) >= 350000\n",
        "ORDER BY view desc\n",
        "\"\"\"\n",
        "spark.sql(e).show()\n",
        "\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Qm12WN9isHBR"
      },
      "outputs": [],
      "source": [
        "# 10. Partition by the \"date_built\" field on the formatted parquet home sales data\n",
        "homes_df.write.partitionBy('yr_built').parquet('parquet_home_sales',mode='overwrite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AZ7BgY61sRqY"
      },
      "outputs": [],
      "source": [
        "# 11. Read the parquet formatted data.\n",
        "parquet_homes_df = spark.read.parquet('parquet_home_sales')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "J6MJkHfvVcvh"
      },
      "outputs": [],
      "source": [
        "# 12. Create a temporary table for the parquet data.\n",
        "parquet_homes_df.createOrReplaceTempView('parquet_temp_home')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Vhb52rU1Sn",
        "outputId": "aab83fec-c1c4-4ee4-dc06-e5fad7104ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|view|AVERAGE_PRICE|\n",
            "+----+-------------+\n",
            "|   4|   1463711.24|\n",
            "|   3|    971965.27|\n",
            "|   2|    792400.89|\n",
            "|   1|    812280.84|\n",
            "|   0|    496564.67|\n",
            "+----+-------------+\n",
            "\n",
            "--- 0.35763120651245117 seconds ---\n"
          ]
        }
      ],
      "source": [
        "# 13. Using the parquet DataFrame, run the last query above, that calculates\n",
        "# the average price of a home per \"view\" rating, rounded to two decimal places,\n",
        "# having an average home price greater than or equal to $350,000.\n",
        "# Determine the runtime and compare it to the cached runtime.\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "e = \"\"\"\n",
        "SELECT\n",
        "  view,\n",
        "  ROUND(AVG(price), 2) AS AVERAGE_PRICE\n",
        "FROM home_sales\n",
        "GROUP BY view\n",
        "HAVING AVG(price) >= 350000\n",
        "ORDER BY view desc\n",
        "\"\"\"\n",
        "spark.sql(e).show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hjjYzQGjtbq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b6c69d-cdb8-424d-e62d-918530ded9b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# 14. Uncache the home_sales temporary table.\n",
        "spark.sql('uncache table home_sales')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Sy9NBvO7tlmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee89db6a-c0eb-4b9c-ab57-e677ab069b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not cached\n"
          ]
        }
      ],
      "source": [
        "# 15. Check if the home_sales is no longer cached\n",
        "if spark.catalog.isCached('home_sales'):\n",
        "  print('home_sales is cached')\n",
        "else:\n",
        "  print('not cached')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si-BNruRUGK3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}